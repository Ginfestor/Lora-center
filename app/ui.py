import os
import logging
import gradio as gr
import threading
import shutil
import requests
from app.trainer import train_lora, log_path
import time
import re
from transformers import AutoModelForCausalLM, AutoTokenizer
from huggingface_hub import HfApi, login, HfFolder
from dotenv import load_dotenv
from peft import PeftModel

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

UPLOAD_DIR = "data/uploads"
ADAPTER_DIR = "adapters"
# –ê–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –º–æ–¥–µ–ª–µ–π –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞
MODELS_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "models")

os.makedirs(UPLOAD_DIR, exist_ok=True)
os.makedirs(ADAPTER_DIR, exist_ok=True)
os.makedirs(MODELS_DIR, exist_ok=True)

# –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
HF_TOKEN = os.getenv("HF_TOKEN")
if not HF_TOKEN:
    logger.warning("HF_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å –º–æ–¥–µ–ª–µ–π
DOWNLOADABLE_MODELS = {}

# –ö—ç—à –¥–ª—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–æ–≤
MODEL_CACHE = {}
TOKENIZER_CACHE = {}

def get_popular_models(hf_token=None):
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Å HuggingFace"""
    try:
        logger.info("–ù–∞—á–∞–ª–æ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π")
        api = HfApi()
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–∫–µ–Ω –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è, –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω
        token = hf_token or HF_TOKEN
        if token:
            logger.info("–°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–∫–µ–Ω HuggingFace")
            HfFolder.save_token(token)
            logger.info("–¢–æ–∫–µ–Ω —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω")
        
        logger.info("–ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –º–æ–¥–µ–ª–∏ —Å HuggingFace")
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        try:
            models = api.list_models(
                filter="text-generation",
                sort="downloads",
                direction=-1,
                limit=50,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ª–∏–º–∏—Ç
                full=True,  # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª—è—Ö
                cardData=True  # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ –∫–∞—Ä—Ç–æ—á–µ–∫ –º–æ–¥–µ–ª–µ–π
            )
            logger.info("–ó–∞–ø—Ä–æ—Å –∫ API —É—Å–ø–µ—à–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω")
        except Exception as api_error:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ API: {str(api_error)}")
            logger.exception("–ü–æ–ª–Ω—ã–π —Å—Ç–µ–∫ –æ—à–∏–±–∫–∏ API:")
            return {}
        
        models_list = list(models)
        logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ {len(models_list)} –º–æ–¥–µ–ª–µ–π")
        
        # –û—Ç–ª–∞–¥–∫–∞: –ø–µ—á–∞—Ç–∞–µ–º –∞—Ç—Ä–∏–±—É—Ç—ã –ø–µ—Ä–≤–æ–π –º–æ–¥–µ–ª–∏
        if models_list and len(models_list) > 0:
            first_model = models_list[0]
            logger.info(f"–ü—Ä–∏–º–µ—Ä –º–æ–¥–µ–ª–∏ (–ø–µ—Ä–≤–∞—è –≤ —Å–ø–∏—Å–∫–µ): {first_model.id}")
            
            # –í—ã–≤–æ–¥–∏–º –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã
            logger.info("–î–æ—Å—Ç—É–ø–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã –º–æ–¥–µ–ª–∏:")
            for attr_name in dir(first_model):
                if not attr_name.startswith("_"):  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–∏–≤–∞—Ç–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã
                    try:
                        attr_value = getattr(first_model, attr_name)
                        # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ –º–µ—Ç–æ–¥, –≤—ã–≤–æ–¥–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ
                        if not callable(attr_value):
                            if attr_name == "cardData" and attr_value:
                                logger.info(f"cardData —Å—Ç—Ä—É–∫—Ç—É—Ä–∞:")
                                for key, value in attr_value.items():
                                    logger.info(f"  - {key}: {type(value)}")
                                    # –î–ª—è model-index –≤—ã–≤–æ–¥–∏–º –ø–æ–¥—Ä–æ–±–Ω–µ–µ
                                    if key == "model-index" and isinstance(value, list) and value:
                                        logger.info(f"    model-index[0] keys: {value[0].keys() if isinstance(value[0], dict) else '–Ω–µ —Å–ª–æ–≤–∞—Ä—å'}")
                            else:
                                logger.info(f"  - {attr_name}: {attr_value}")
                    except Exception as e:
                        logger.info(f"  - {attr_name}: <–æ—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞: {str(e)}>")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ª–æ–≤–∞—Ä—å –º–æ–¥–µ–ª–µ–π
        model_dict = {}
        for model in models_list:
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –º–æ–¥–µ–ª—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
                if hasattr(model, 'tags') and "text-generation" in model.tags:
                    # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
                    model_info = {
                        'id': model.id,
                        'downloads': getattr(model, 'downloads', 0),
                        'likes': getattr(model, 'likes', 0),
                        'tags': getattr(model, 'tags', []),
                        'pipeline_tag': getattr(model, 'pipeline_tag', ''),
                        'description': getattr(model, 'description', '–û–ø–∏—Å–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç'),
                        'cardData': getattr(model, 'cardData', {})
                    }
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º id –º–æ–¥–µ–ª–∏ –∫–∞–∫ –∫–ª—é—á
                    model_dict[model.id] = model_info
                    logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å: {model.id} (–∑–∞–≥—Ä—É–∑–æ–∫: {model_info['downloads']})")
            except Exception as model_error:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –º–æ–¥–µ–ª–∏ {model.id}: {str(model_error)}")
                continue
        
        logger.info(f"–ò—Ç–æ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ {len(model_dict)} –º–æ–¥–µ–ª–µ–π")
        logger.info(f"–°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π: {list(model_dict.keys())}")
        return model_dict
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {str(e)}")
        logger.exception("–ü–æ–ª–Ω—ã–π —Å—Ç–µ–∫ –æ—à–∏–±–∫–∏:")
        return {}

def check_model_availability(model_name):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
    model_path = os.path.join(MODELS_DIR, model_name)
    return os.path.exists(model_path)

def get_available_models():
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    available_models = {}
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–µ–π –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    logger.info(f"–ü–æ–∏—Å–∫ –º–æ–¥–µ–ª–µ–π –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {MODELS_DIR}")
    if os.path.exists(MODELS_DIR):
        logger.info(f"–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –º–æ–¥–µ–ª–µ–π: {os.listdir(MODELS_DIR)}")
        for model_dir in os.listdir(MODELS_DIR):
            model_path = os.path.join(MODELS_DIR, model_dir)
            if os.path.isdir(model_path):
                logger.info(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –º–æ–¥–µ–ª–∏: {model_dir}")
                # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –∏—â–µ–º —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–∏
                has_model_files = False
                model_files = []
                for root, _, files in os.walk(model_path):
                    model_files.extend([f for f in files if f.endswith('.bin') or f.endswith('.safetensors')])
                    if any(file.endswith('.bin') or file.endswith('.safetensors') for file in files):
                        has_model_files = True
                        break
                
                logger.info(f"–ù–∞–π–¥–µ–Ω—ã —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–∏: {model_files}")
                
                if has_model_files:
                    # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏ –∏–∑ model_info.json
                    info_path = os.path.join(model_path, "model_info.json")
                    if os.path.exists(info_path):
                        try:
                            with open(info_path, "r", encoding="utf-8") as f:
                                import json
                                model_info = json.load(f)
                                model_name = model_info.get("model_name", model_dir)
                                model_id = model_info.get("model_id", model_dir)
                                available_models[model_name] = model_id
                                logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å –∏–∑ model_info.json: {model_name} -> {model_id}")
                        except Exception as e:
                            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ model_info.json –¥–ª—è {model_dir}: {str(e)}")
                            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–º—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
                            available_models[model_dir] = model_dir.replace('_', '/')
                            logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å –∏–∑ –∏–º–µ–Ω–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {model_dir} -> {model_dir.replace('_', '/')}")
                    else:
                        # –ï—Å–ª–∏ –Ω–µ—Ç —Ñ–∞–π–ª–∞ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–º—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
                        available_models[model_dir] = model_dir.replace('_', '/')
                        logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å –∏–∑ –∏–º–µ–Ω–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {model_dir} -> {model_dir.replace('_', '/')}")
    
    logger.info(f"–ò—Ç–æ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(available_models)}")
    logger.info(f"–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏: {available_models}")
    return available_models

def update_transformers():
    """–û–±–Ω–æ–≤–ª—è–µ—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫—É transformers –¥–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π –≤–µ—Ä—Å–∏–∏"""
    try:
        logger.info("–ù–∞—á–∞–ª–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ transformers")
        import subprocess
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –æ–±–Ω–æ–≤–∏—Ç—å —á–µ—Ä–µ–∑ pip
        result = subprocess.run(
            ["pip", "install", "--upgrade", "transformers"],
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            logger.info("–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ transformers —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∞")
            return "‚úÖ –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ transformers —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å —Å–Ω–æ–≤–∞."
        else:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —á–µ—Ä–µ–∑ pip: {result.stderr}")
            
            # –ï—Å–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ pip –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ, –ø—Ä–æ–±—É–µ–º —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏–∑ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
            logger.info("–ü–æ–ø—ã—Ç–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ transformers –∏–∑ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è GitHub")
            result = subprocess.run(
                ["pip", "install", "git+https://github.com/huggingface/transformers.git"],
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                logger.info("–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ transformers —É—Å–ø–µ—à–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∏–∑ GitHub")
                return "‚úÖ –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ transformers —É—Å–ø–µ—à–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∏–∑ GitHub. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å —Å–Ω–æ–≤–∞."
            else:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–µ –∏–∑ GitHub: {result.stderr}")
                return f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫—É transformers. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≤—Ä—É—á–Ω—É—é –≤—ã–ø–æ–ª–Ω–∏—Ç—å: \n```\npip install --upgrade transformers\n```\n–∏–ª–∏\n```\npip install git+https://github.com/huggingface/transformers.git\n```"
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ transformers: {str(e)}")
        return f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏: {str(e)}"

def download_model(model_name, model_id, hf_token):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å"""
    try:
        logger.info(f"–ù–∞—á–∞–ª–æ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ {model_name}")
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º ID –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
        model_path = os.path.join(MODELS_DIR, model_id.replace('/', '_'))
        os.makedirs(model_path, exist_ok=True)
        
        # –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–∞ HuggingFace
        if hf_token:
            login(token=hf_token)
            logger.info("–£—Å–ø–µ—à–Ω–∞—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–∞ HuggingFace")
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
        try:
            api = HfApi()
            model_info = api.model_info(
                repo_id=model_id,
                token=hf_token
            )
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –º–æ–¥–µ–ª—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ç–µ–∫—Å—Ç–∞
            allowed_types = ['text-generation', 'text2text-generation', 'any-to-any', 'multi_modality']
            
            if hasattr(model_info, 'pipeline_tag') and model_info.pipeline_tag not in allowed_types:
                error_msg = f"‚ùå –ú–æ–¥–µ–ª—å {model_name} –∏–º–µ–µ—Ç —Ç–∏–ø {model_info.pipeline_tag}, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞"
                logger.error(error_msg)
                return error_msg
        
        except Exception as info_error:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏ {model_name}: {str(info_error)}")
            logger.info("–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏ –±–µ–∑ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç–∏–ø–∞")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞
        try:
            tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=hf_token)
            tokenizer.save_pretrained(model_path)
            logger.info(f"–¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –¥–ª—è –º–æ–¥–µ–ª–∏ {model_name} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω")
        except Exception as tokenizer_error:
            error_msg = f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞: {str(tokenizer_error)}"
            logger.error(error_msg)
            return error_msg
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
        try:
            model = AutoModelForCausalLM.from_pretrained(
                model_id,
                torch_dtype="auto",
                device_map="auto",
                use_auth_token=hf_token
            )
            model.save_pretrained(model_path)
            logger.info(f"–ú–æ–¥–µ–ª—å {model_name} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            
            # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª–∏
            with open(os.path.join(model_path, "model_info.json"), "w", encoding="utf-8") as f:
                import json
                json.dump({
                    "model_name": model_name,
                    "model_id": model_id,
                    "download_date": time.strftime("%Y-%m-%d %H:%M:%S")
                }, f, ensure_ascii=False, indent=2)
            
            return f"‚úÖ –ú–æ–¥–µ–ª—å {model_name} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞"
        except Exception as model_error:
            error_msg = f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏ {model_name}: {str(model_error)}"
            logger.error(error_msg)
            
            # –ï—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–µ —É–¥–∞–ª–∞—Å—å, —É–¥–∞–ª—è–µ–º —á–∞—Å—Ç–∏—á–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            try:
                shutil.rmtree(model_path)
                logger.info(f"–£–¥–∞–ª–µ–Ω—ã —á–∞—Å—Ç–∏—á–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–∏ {model_name}")
            except Exception as cleanup_error:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —á–∞—Å—Ç–∏—á–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {str(cleanup_error)}")
            return error_msg
            
    except Exception as e:
        error_msg = f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏ {model_name}: {str(e)}"
        logger.error(error_msg)
        return error_msg

def save_file(file):
    filepath = os.path.join(UPLOAD_DIR, file.name)
    with open(filepath, "wb") as f:
        shutil.copyfileobj(file, f)
    return f"–ó–∞–≥—Ä—É–∂–µ–Ω —Ñ–∞–π–ª: {file.name}"

def start_training(model, r, alpha, dropout):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è LoRA"""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –º–æ–¥–µ–ª—å —É–∫–∞–∑–∞–Ω–∞
    if not model:
        return "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"
    
    # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –≤—ã–±—Ä–∞–Ω–∞ –∏–∑ –≤—ã–ø–∞–¥–∞—é—â–µ–≥–æ —Å–ø–∏—Å–∫–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ—ë ID
    available_models = get_available_models()
    if model in available_models:
        model_id = available_models[model]
    else:
        # –ò–Ω–∞—á–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–∫–∞–∑–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–∞–ø—Ä—è–º—É—é
        model_id = model
    
    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
        train_thread = threading.Thread(
            target=train_lora,
            args=(model_id, r, alpha, dropout),
            daemon=True
        )
        train_thread.start()
        
        return f"–ù–∞—á–∞—Ç–æ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ {model_id}. –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: r={r}, alpha={alpha}, dropout={dropout}"
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –æ–±—É—á–µ–Ω–∏—è: {str(e)}")
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –æ–±—É—á–µ–Ω–∏—è: {str(e)}"

def get_logs():
    if os.path.exists(log_path):
        with open(log_path, "r") as f:
            return f.read()
    return "–õ–æ–≥–∏ –ø–æ–∫–∞ –ø—É—Å—Ç—ã"

def chatbot(message, history, model_name, lora_selector="–ù–µ—Ç"):
    """–í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å —á–∞—Ç-–±–æ—Ç–æ–º —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –º–æ–¥–µ–ª—å –≤—ã–±—Ä–∞–Ω–∞
    if not model_name:
        return "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –≤ –≤—ã–ø–∞–¥–∞—é—â–µ–º —Å–ø–∏—Å–∫–µ"
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        available_models = get_available_models()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—ã–±—Ä–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–æ—Å—Ç—É–ø–Ω–∞
        if model_name not in available_models:
            return "–í—ã–±—Ä–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å."
        
        # –ü–æ–ª—É—á–∞–µ–º ID –º–æ–¥–µ–ª–∏
        model_id = available_models[model_name]
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
        model_path = os.path.join(MODELS_DIR, model_id.replace("/", "_"))
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –º–æ–¥–µ–ª—å —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        if not os.path.exists(model_path):
            return f"–ú–æ–¥–µ–ª—å {model_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–æ –ø—É—Ç–∏ {model_path}"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –º–æ–¥–µ–ª—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–µ–π –≤–µ—Ä—Ö–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è –∏–ª–∏ –ø–æ–¥–∫–∞—Ç–∞–ª–æ–≥–æ–º
        model_config_path = os.path.join(model_path, "config.json")
        if not os.path.exists(model_config_path):
            # –ò—â–µ–º –ø–æ–¥–∫–∞—Ç–∞–ª–æ–≥–∏ —Å —Ñ–∞–π–ª–æ–º config.json
            subdirs = [d for d in os.listdir(model_path) if os.path.isdir(os.path.join(model_path, d))]
            for subdir in subdirs:
                subdir_path = os.path.join(model_path, subdir)
                if os.path.exists(os.path.join(subdir_path, "config.json")):
                    logger.info(f"–ù–∞–π–¥–µ–Ω–∞ –º–æ–¥–µ–ª—å –≤ –ø–æ–¥–∫–∞—Ç–∞–ª–æ–≥–µ: {subdir}")
                    model_path = subdir_path
                    break
            else:
                return f"–ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª config.json –¥–ª—è –º–æ–¥–µ–ª–∏ {model_name}"
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä (–∏—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à)
        if model_name not in TOKENIZER_CACHE:
            logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –¥–ª—è –º–æ–¥–µ–ª–∏ {model_name} –∏–∑ {model_path}")
            TOKENIZER_CACHE[model_name] = AutoTokenizer.from_pretrained(model_path)
        tokenizer = TOKENIZER_CACHE[model_name]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ LoRA –∞–¥–∞–ø—Ç–µ—Ä–∞
        use_lora = lora_selector != "–ù–µ—Ç"
        lora_path = None
        
        if use_lora:
            # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ LoRA –∞–¥–∞–ø—Ç–µ—Ä—É
            lora_path = os.path.join(ADAPTER_DIR, lora_selector)
            logger.info(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ LoRA –∞–¥–∞–ø—Ç–µ—Ä–∞: {lora_selector}, –ø—É—Ç—å: {lora_path}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –∞–¥–∞–ø—Ç–µ—Ä–∞
            if not os.path.exists(lora_path):
                return f"LoRA –∞–¥–∞–ø—Ç–µ—Ä {lora_selector} –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏ {lora_path}"
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ñ–∞–π–ª–æ–≤
            adapter_config = os.path.join(lora_path, "adapter_config.json")
            if not os.path.exists(adapter_config):
                return f"–ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª adapter_config.json –¥–ª—è LoRA –∞–¥–∞–ø—Ç–µ—Ä–∞ {lora_selector}"
        
        # –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –¥–ª—è –∫—ç—à–∞ –º–æ–¥–µ–ª–∏ (—É—á–∏—Ç—ã–≤–∞–µ–º LoRA)
        cache_key = f"{model_name}_{lora_selector}" if use_lora else model_name
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å (–∏—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à)
        if cache_key not in MODEL_CACHE:
            logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ {model_name} –¥–ª—è —á–∞—Ç–∞ –∏–∑ {model_path}")
            # –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å
            base_model = AutoModelForCausalLM.from_pretrained(
                model_path,
                torch_dtype="auto",
                device_map="auto",
                local_files_only=True
            )
            
            # –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è LoRA, –∑–∞–≥—Ä—É–∂–∞–µ–º –∞–¥–∞–ø—Ç–µ—Ä
            if use_lora:
                try:
                    logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ LoRA –∞–¥–∞–ø—Ç–µ—Ä–∞ –∏–∑ {lora_path}")
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º LoRA –∞–¥–∞–ø—Ç–µ—Ä
                    model = PeftModel.from_pretrained(base_model, lora_path)
                    logger.info(f"LoRA –∞–¥–∞–ø—Ç–µ—Ä —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω")
                except Exception as lora_error:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ LoRA –∞–¥–∞–ø—Ç–µ—Ä–∞: {str(lora_error)}")
                    return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ LoRA –∞–¥–∞–ø—Ç–µ—Ä–∞: {str(lora_error)}"
            else:
                model = base_model
            
            MODEL_CACHE[cache_key] = model
        else:
            logger.info(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ {cache_key}")
        
        model = MODEL_CACHE[cache_key]
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞
        prompt = ""
        for usr_msg, bot_msg in history:
            if usr_msg and bot_msg:
                prompt += f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {usr_msg}\n–ë–æ—Ç: {bot_msg}\n"
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        prompt += f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {message}\n–ë–æ—Ç:"
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
        outputs = model.generate(
            **inputs,
            max_new_tokens=200,
            temperature=0.7,
            top_p=0.9,
            repetition_penalty=1.2,
            do_sample=True
        )
        
        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ –æ—Ç–≤–µ—Ç –±–æ—Ç–∞
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π –æ—Ç–≤–µ—Ç –±–æ—Ç–∞
            bot_response = response.split("–ë–æ—Ç:")[-1].strip()
        except:
            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–¥–µ–ª–∏—Ç—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–µ—Å—å –æ—Ç–≤–µ—Ç
            bot_response = response
        
        return bot_response
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}")
        logger.exception("–ü–æ–ª–Ω—ã–π —Å—Ç–µ–∫ –æ—à–∏–±–∫–∏:")
        return f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}"

def handle_download(model_name, token):
    if model_name:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π ID –º–æ–¥–µ–ª–∏ –∏–∑ —Å–ª–æ–≤–∞—Ä—è
        model_info = DOWNLOADABLE_MODELS[model_name]
        model_id = model_info['id'] if isinstance(model_info, dict) else model_info
        return download_model(model_name, model_id, token)
    return "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å"

def update_model_list(token):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –≤ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ"""
    global DOWNLOADABLE_MODELS
    try:
        logger.info("–ù–∞—á–∞–ª–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π")
        # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ —Å HuggingFace
        logger.info("–ü–æ–ª—É—á–∞–µ–º –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Å HuggingFace")
        popular_models = get_popular_models(token)
        
        if popular_models:
            logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ {len(popular_models)} –º–æ–¥–µ–ª–µ–π")
            # –û–±–Ω–æ–≤–ª—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –º–æ–¥–µ–ª–µ–π
            DOWNLOADABLE_MODELS = popular_models
            choices = list(popular_models.keys())
            logger.info(f"–°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è –≤—ã–ø–∞–¥–∞—é—â–µ–≥–æ —Å–ø–∏—Å–∫–∞: {choices}")
            if not choices:
                logger.warning("–ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π")
            return choices
        else:
            logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π")
            DOWNLOADABLE_MODELS = {}  # –û—á–∏—â–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –º–æ–¥–µ–ª–µ–π
            return []
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {str(e)}")
        logger.exception("–ü–æ–ª–Ω—ã–π —Å—Ç–µ–∫ –æ—à–∏–±–∫–∏:")
        DOWNLOADABLE_MODELS = {}  # –û—á–∏—â–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –º–æ–¥–µ–ª–µ–π
        return []

def get_model_info(model_id, hf_token=None):
    """–ü–æ–ª—É—á–∞–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏ —Å HuggingFace"""
    try:
        logger.info(f"–ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏ {model_id}")
        api = HfApi()
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–∫–µ–Ω –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è, –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω
        token = hf_token or HF_TOKEN
        if token:
            HfFolder.save_token(token)
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
        try:
            model_info = api.model_info(
                repo_id=model_id,
                token=token
            )
            logger.info(f"–£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏ {model_id}")
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
            model_data = {
                'id': model_id,
                'downloads': getattr(model_info, 'downloads', 0),
                'likes': getattr(model_info, 'likes', 0),
                'tags': getattr(model_info, 'tags', []),
                'pipeline_tag': getattr(model_info, 'pipeline_tag', ''),
                'description': getattr(model_info, 'description', ''),
                'cardData': getattr(model_info, 'cardData', {})
            }
            
            # –û—Ç–ª–∞–¥–∫–∞: –≤—ã–≤–æ–¥–∏–º –≤—Å—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
            logger.info(f"–î–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ {model_id}:")
            for key, value in model_data.items():
                if key != 'cardData':  # –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –¥–∞–Ω–Ω—ã—Ö
                    logger.info(f"  - {key}: {value}")
            
            return model_data
            
        except Exception as api_error:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏ {model_id}: {str(api_error)}")
            logger.exception("–ü–æ–ª–Ω—ã–π —Å—Ç–µ–∫ –æ—à–∏–±–∫–∏ API:")
            return None
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏ {model_id}: {str(e)}")
        logger.exception("–ü–æ–ª–Ω—ã–π —Å—Ç–µ–∫ –æ—à–∏–±–∫–∏:")
        return None

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫—Ä–∞—Ç–∫–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –º–æ–¥–µ–ª–∏
def get_model_description(model_name):
    if not model_name or model_name not in DOWNLOADABLE_MODELS:
        return "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"
    
    # –ü–æ–ª—É—á–∞–µ–º –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫—ç—à–∞
    model_info = DOWNLOADABLE_MODELS[model_name]
    
    if isinstance(model_info, dict):
        # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –Ω–∞–ø—Ä—è–º—É—é
        detailed_info = get_model_info(model_name)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞
        if detailed_info:
            model_info = detailed_info
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –º–æ–¥–µ–ª–∏
        downloads = model_info.get('downloads', 0)
        likes = model_info.get('likes', 0)
        tags = model_info.get('tags', [])
        card_data = model_info.get('cardData', {})
        
        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –æ–ø–∏—Å–∞–Ω–∏–µ –≤ —Ä–∞–∑–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö
        description = ''
        
        # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –ø–æ–ª–µ description
        if not description:
            description = model_info.get('description', '')
        
        # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤ cardData.model-index[0].description
        if not description and card_data:
            model_index = card_data.get('model-index', [])
            if model_index and isinstance(model_index, list) and len(model_index) > 0:
                first_entry = model_index[0]
                if isinstance(first_entry, dict) and 'description' in first_entry:
                    description = first_entry.get('description', '')
        
        # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤ cardData.metadata
        if not description and card_data:
            metadata = card_data.get('metadata', {})
            if isinstance(metadata, dict):
                description = metadata.get('description', '')
        
        # –ï—Å–ª–∏ –æ–ø–∏—Å–∞–Ω–∏–µ –≤—Å—ë —Ä–∞–≤–Ω–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
        if not description:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–º–µ–Ω–∏ –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
            description = f"–ú–æ–¥–µ–ª—å {model_name} –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞."
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –ø–æ –∏–º–µ–Ω–∏
            architecture = None
            if "gpt" in model_name.lower():
                architecture = "GPT"
            elif "llama" in model_name.lower():
                architecture = "LLaMA"
            elif "mistral" in model_name.lower():
                architecture = "Mistral"
            elif "falcon" in model_name.lower():
                architecture = "Falcon"
            elif "phi" in model_name.lower():
                architecture = "Phi"
            
            if architecture:
                description += f" –û—Å–Ω–æ–≤–∞–Ω–∞ –Ω–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ {architecture}."
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏
        model_size = "–ù–µ —É–∫–∞–∑–∞–Ω"
        
        # 1. –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∫–∞—Ä—Ç–æ—á–∫–∏
        if card_data:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ª–µ model-index
            model_index = card_data.get('model-index', [])
            if model_index and isinstance(model_index, list) and len(model_index) > 0:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
                first_entry = model_index[0]
                if isinstance(first_entry, dict):
                    # –ò—â–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
                    params = first_entry.get('params', {})
                    if params:
                        param_count = params.get('n_params', None)
                        if param_count:
                            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —É–¥–æ–±–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç (–º–∏–ª–ª–∏–∞—Ä–¥—ã –∏–ª–∏ –º–∏–ª–ª–∏–æ–Ω—ã)
                            if param_count >= 1_000_000_000:
                                model_size = f"{param_count / 1_000_000_000:.1f}B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"
                            else:
                                model_size = f"{param_count / 1_000_000:.1f}M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"
        
        # 2. –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö, –∏—â–µ–º –≤ ID –º–æ–¥–µ–ª–∏ –∏–ª–∏ —Ç–µ–≥–∞—Ö
        if model_size == "–ù–µ —É–∫–∞–∑–∞–Ω":
            # –ò—â–µ–º –≤ ID –º–æ–¥–µ–ª–∏
            size_patterns = [
                r'(\d+\.?\d*)b\b', # –Ω–∞–ø—Ä–∏–º–µ—Ä, 7b, 7.5b
                r'(\d+\.?\d*)[_-]?b\b', # –Ω–∞–ø—Ä–∏–º–µ—Ä, 7-b, 7_b
                r'(\d+\.?\d*)B\b', # –Ω–∞–ø—Ä–∏–º–µ—Ä, 7B, 13B
                r'(\d+\.?\d*)[_-]?B\b', # –Ω–∞–ø—Ä–∏–º–µ—Ä, 7-B, 7_B
                r'(\d+\.?\d*)[_-]?billion', # –Ω–∞–ø—Ä–∏–º–µ—Ä, 7-billion
                r'(\d+\.?\d*)[_-]?bn\b', # –Ω–∞–ø—Ä–∏–º–µ—Ä, 7bn
                r'-(\d+\.?\d*)b\b', # –Ω–∞–ø—Ä–∏–º–µ—Ä, Llama-7b
                r'-(\d+\.?\d*)B\b' # –Ω–∞–ø—Ä–∏–º–µ—Ä, Llama-7B
            ]
            
            # –ò—â–µ–º –≤ ID –º–æ–¥–µ–ª–∏
            for pattern in size_patterns:
                match = re.search(pattern, model_name, re.IGNORECASE)
                if match:
                    model_size = f"{match.group(1)}B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"
                    break
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ ID, –∏—â–µ–º –≤ —Ç–µ–≥–∞—Ö
            if model_size == "–ù–µ —É–∫–∞–∑–∞–Ω" and tags:
                tags_str = " ".join(tags) if isinstance(tags, list) else str(tags)
                for pattern in size_patterns:
                    match = re.search(pattern, tags_str, re.IGNORECASE)
                    if match:
                        model_size = f"{match.group(1)}B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"
                        break
        
        # –û–±—Ä–µ–∑–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –µ—Å–ª–∏ –æ–Ω–æ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ
        short_desc = description[:300] + '...' if len(description) > 300 else description
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–µ–≥–∏ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if isinstance(tags, list):
            tags_str = ', '.join(tags) if tags else "–ù–µ—Ç —Ç–µ–≥–æ–≤"
        else:
            tags_str = str(tags) if tags else "–ù–µ—Ç —Ç–µ–≥–æ–≤"
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫—Ä–∞—Å–∏–≤—ã–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π –±–ª–æ–∫
        info_block = [
            f"**–ú–æ–¥–µ–ª—å:** {model_name}",
            f"**–†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏:** {model_size}",
            f"**–û–ø–∏—Å–∞–Ω–∏–µ:** {short_desc}",
            f"**–ó–∞–≥—Ä—É–∑–∫–∏:** {downloads:,}",
            f"**–õ–∞–π–∫–∏:** {likes}"
        ]
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–≥–∏, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∏—Ö –Ω–µ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ
        if len(tags_str) < 500:
            info_block.append(f"**–¢–µ–≥–∏:** {tags_str}")
        else:
            info_block.append(f"**–¢–µ–≥–∏:** {len(tags) if isinstance(tags, list) else '–º–Ω–æ–≥–æ'} —Ç–µ–≥–æ–≤")
        
        return "\n\n".join(info_block)
    else:
        return f"**–ú–æ–¥–µ–ª—å:** {model_name}\n\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"

def create_ui():
    global DOWNLOADABLE_MODELS
    
    # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
    try:
        model_choices = update_model_list(HF_TOKEN)
        logger.info(f"–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –º–æ–¥–µ–ª–∏: {model_choices}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–µ–π: {str(e)}")
        model_choices = []
    
    # –°–æ–∑–¥–∞–µ–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
    with gr.Blocks(title="LoRA Center") as demo:
        gr.Markdown("# –¶–µ–Ω—Ç—Ä –æ–±—É—á–µ–Ω–∏—è LoRA-–±–æ—Ç–æ–≤")

        # –í–∫–ª–∞–¥–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π
        with gr.Tab(label="üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π"):
            gr.Markdown("### –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏")
            hf_token = gr.Textbox(
                label="HuggingFace API —Ç–æ–∫–µ–Ω",
                type="password",
                value=HF_TOKEN,
                placeholder="hf_..."
            )
            
            with gr.Row():
                with gr.Column(scale=3):
                    gr.Markdown("#### –í—ã–±–æ—Ä –∏–∑ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
                    refresh_button = gr.Button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π")
                    
                    # –í–∞–∂–Ω–æ: —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—ã–±–æ—Ä–∞ —Å –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
                    model_download = gr.Dropdown(
                        label="–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏",
                        choices=model_choices,
                        interactive=True
                    )
                    
                with gr.Column(scale=2):
                    gr.Markdown("#### –ü—Ä—è–º–æ–π –≤–≤–æ–¥ ID –º–æ–¥–µ–ª–∏")
                    custom_model_id = gr.Textbox(
                        label="–í–≤–µ–¥–∏—Ç–µ HuggingFace ID –º–æ–¥–µ–ª–∏",
                        placeholder="–Ω–∞–ø—Ä–∏–º–µ—Ä: mistralai/Mistral-7B-v0.1"
                    )
                    custom_download_button = gr.Button("–ó–∞–≥—Ä—É–∑–∏—Ç—å —É–∫–∞–∑–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å")
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
            model_info = gr.Markdown("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏")
            
            with gr.Row():
                download_button = gr.Button("–ó–∞–≥—Ä—É–∑–∏—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å")
                download_status = gr.Textbox(label="–°—Ç–∞—Ç—É—Å –∑–∞–≥—Ä—É–∑–∫–∏")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –±–ª–æ–∫ —Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ transformers
            with gr.Accordion("–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ü–∏–∏", open=False):
                gr.Markdown("#### –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞–º–∏")
                gr.Markdown("–ï—Å–ª–∏ –≤—ã —Å—Ç–æ–ª–∫–Ω—É–ª–∏—Å—å —Å –æ—à–∏–±–∫–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ –∏–∑-–∑–∞ –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –æ–±–Ω–æ–≤–∏—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫—É transformers:")
                update_transformers_button = gr.Button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å transformers")
                transformers_status = gr.Textbox(label="–°—Ç–∞—Ç—É—Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è")
                
                # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è transformers
                update_transformers_button.click(
                    fn=update_transformers,
                    inputs=[],
                    outputs=transformers_status
                )
            
            debug_output = gr.Textbox(label="–û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è", visible=False)
            
            # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π
            refresh_button.click(
                fn=update_model_list,
                inputs=hf_token,
                outputs=model_download
            )
            
            # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏
            model_download.change(
                fn=get_model_description,
                inputs=model_download,
                outputs=model_info
            )
            
            # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∑–∞–≥—Ä—É–∑–∫–∏ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
            download_button.click(
                fn=handle_download,
                inputs=[model_download, hf_token],
                outputs=download_status
            )
            
            # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ –ø–æ ID
            def download_custom_model(model_id, token):
                if not model_id or not model_id.strip():
                    return "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ ID –º–æ–¥–µ–ª–∏"
                
                return download_model(model_id, model_id, token)
            
            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤–≤–µ–¥–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
            custom_model_id.change(
                fn=lambda model_id: get_model_description(model_id) if model_id and model_id.strip() else "–í–≤–µ–¥–∏—Ç–µ ID –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏",
                inputs=custom_model_id,
                outputs=model_info
            )
            
            # –ó–∞–ø—É—Å–∫ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–≤–µ–¥–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
            custom_download_button.click(
                fn=download_custom_model,
                inputs=[custom_model_id, hf_token],
                outputs=download_status
            )

        # –û—Å—Ç–∞–ª—å–Ω—ã–µ –≤–∫–ª–∞–¥–∫–∏ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
        with gr.Tab(label="üì§ –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤"):
            upload = gr.File(file_types=[".txt", ".docx", ".pdf"], file_count="multiple")
            upload_button = gr.Button("–ó–∞–≥—Ä—É–∑–∏—Ç—å")
            output = gr.Textbox()
            upload_button.click(fn=lambda files: "\n".join([save_file(f) for f in files]), inputs=upload, outputs=output)

        with gr.Tab(label="üß† –û–±—É—á–µ–Ω–∏–µ LoRA"):
            gr.Markdown("### –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            
            # –§–∞–π–ª–æ–≤—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏—è
            file_output = gr.File(
                file_count="multiple",
                label="–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (.txt)",
                file_types=[".txt"],
                type="filepath"
            )
            
            with gr.Row():
                upload_button = gr.Button("üì§ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª—ã")
                clear_files_button = gr.Button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å —Ñ–∞–π–ª—ã")
            
            upload_info = gr.Markdown("")
            
            gr.Markdown("### –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è")
            
            # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            with gr.Row():
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π
                model_status = gr.Markdown("–ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É '–û–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π' –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
            
            with gr.Row():
                model_selector = gr.Dropdown(
                    label="–ú–æ–¥–µ–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è",
                    choices=[],  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏
                    interactive=True
                )
                refresh_models_button = gr.Button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π")
            
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã LoRA
            with gr.Row():
                lora_r = gr.Slider(label="Rank (r)", minimum=1, maximum=64, value=8, step=1)
                lora_alpha = gr.Slider(label="Alpha", minimum=1, maximum=64, value=32, step=1)
                lora_dropout = gr.Slider(label="Dropout", minimum=0.0, maximum=1.0, value=0.05, step=0.01)
            
            # –ö–Ω–æ–ø–∫–∞ –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è
            train_button = gr.Button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ")
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ—Ü–µ—Å—Å–µ
            train_info = gr.Markdown("")
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤
            def upload_training_files(files):
                if not files:
                    return "–§–∞–π–ª—ã –Ω–µ –≤—ã–±—Ä–∞–Ω—ã"
                
                uploaded_count = 0
                for file in files:
                    try:
                        # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –µ–≥–æ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ
                        file_path = file.name if hasattr(file, 'name') else file
                        if os.path.exists(file_path):
                            # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∑–∞–≥—Ä—É–∑–æ–∫
                            destination = os.path.join(UPLOAD_DIR, os.path.basename(file_path))
                            shutil.copy2(file_path, destination)
                            logger.info(f"–§–∞–π–ª {file_path} —É—Å–ø–µ—à–Ω–æ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω –≤ {destination}")
                            uploaded_count += 1
                        else:
                            logger.error(f"–§–∞–π–ª {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞: {str(e)}")
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
                txt_files = [f for f in os.listdir(UPLOAD_DIR) if f.endswith('.txt') and os.path.isfile(os.path.join(UPLOAD_DIR, f))]
                logger.info(f"–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ .txt –≤ {UPLOAD_DIR}: {len(txt_files)}")
                
                if uploaded_count > 0:
                    return f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {uploaded_count} —Ñ–∞–π–ª–æ–≤ –≤ {UPLOAD_DIR}. –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {len(txt_files)}"
                else:
                    return "–û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª—ã. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥."
            
            upload_button.click(
                fn=upload_training_files,
                inputs=file_output,
                outputs=upload_info
            )
            
            # –û—á–∏—Å—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤
            def clear_files():
                for file in os.listdir(UPLOAD_DIR):
                    file_path = os.path.join(UPLOAD_DIR, file)
                    if os.path.isfile(file_path):
                        os.remove(file_path)
                return "–í—Å–µ —Ñ–∞–π–ª—ã —É–¥–∞–ª–µ–Ω—ã"
            
            clear_files_button.click(fn=clear_files, outputs=upload_info)
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π
            def update_model_selector():
                models, status_text = refresh_train_models()
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º gr.update() –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –≤ Gradio 4.x
                return gr.update(choices=models, value=models[0] if models else None), status_text
                
            refresh_models_button.click(
                fn=update_model_selector,
                outputs=[model_selector, model_status]
            )
            
            # –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è
            train_button.click(
                fn=start_training,
                inputs=[model_selector, lora_r, lora_alpha, lora_dropout],
                outputs=train_info
            )

        with gr.Tab(label="üìä –õ–æ–≥–∏ –æ–±—É—á–µ–Ω–∏—è"):
            log_output = gr.Textbox(label="–õ–æ–≥–∏", lines=20)
            refresh_button = gr.Button("–û–±–Ω–æ–≤–∏—Ç—å –ª–æ–≥–∏")
            refresh_button.click(get_logs, outputs=log_output)
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ª–æ–≥–æ–≤ –∫–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥
            demo.load(get_logs, outputs=log_output, every=5)

        with gr.Tab(label="ü§ñ –ß–∞—Ç —Å –±–æ—Ç–æ–º"):
            with gr.Row():
                chat_model_selector = gr.Dropdown(
                    label="–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è —á–∞—Ç–∞",
                    choices=[],  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏
                    interactive=True
                )
                refresh_chat_models_button = gr.Button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π")
                clear_cache_button = gr.Button("üßπ –û—á–∏—Å—Ç–∏—Ç—å –∫—ç—à –º–æ–¥–µ–ª–µ–π")
            
            # –°—Ç–∞—Ç—É—Å –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π –¥–ª—è —á–∞—Ç–∞
            chat_model_status = gr.Markdown("–ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É '–û–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π' –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤—ã–±–æ—Ä LoRA –∞–¥–∞–ø—Ç–µ—Ä–∞
            with gr.Row():
                lora_selector = gr.Dropdown(
                    label="LoRA –∞–¥–∞–ø—Ç–µ—Ä (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)",
                    choices=["–ù–µ—Ç"],  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏
                    value="–ù–µ—Ç",
                    interactive=True
                )
                refresh_loras_button = gr.Button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ LoRA –∞–¥–∞–ø—Ç–µ—Ä–æ–≤")
            
            # –°—Ç–∞—Ç—É—Å –∑–∞–≥—Ä—É–∑–∫–∏ LoRA –∞–¥–∞–ø—Ç–µ—Ä–æ–≤
            lora_status = gr.Markdown("–ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É '–û–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ LoRA –∞–¥–∞–ø—Ç–µ—Ä–æ–≤' –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∞–¥–∞–ø—Ç–µ—Ä–æ–≤")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è —á–∞—Ç–∞
            def update_chat_models():
                models, status_text = refresh_train_models()  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç—É –∂–µ —Ñ—É–Ω–∫—Ü–∏—é, —á—Ç–æ –∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
                return gr.update(choices=models, value=models[0] if models else None), status_text
            
            refresh_chat_models_button.click(
                fn=update_chat_models,
                outputs=[chat_model_selector, chat_model_status]
            )
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ LoRA –∞–¥–∞–ø—Ç–µ—Ä–æ–≤
            def update_loras():
                loras = get_available_loras()
                lora_choices = ["–ù–µ—Ç"] + [lora["name"] for lora in loras]
                status_text = f"–ù–∞–π–¥–µ–Ω–æ {len(loras)} LoRA –∞–¥–∞–ø—Ç–µ—Ä–æ–≤"
                return gr.update(choices=lora_choices, value="–ù–µ—Ç"), status_text
            
            refresh_loras_button.click(
                fn=update_loras,
                outputs=[lora_selector, lora_status]
            )
            
            # –û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ –º–æ–¥–µ–ª–µ–π
            clear_cache_button.click(
                fn=lambda: clear_model_cache(),
                outputs=chat_model_status
            )
            
            # –ü—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏ –æ—á–∏—â–∞–µ–º –∫—ç—à, –∫—Ä–æ–º–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
            chat_model_selector.change(
                fn=clear_model_cache,
                inputs=chat_model_selector,
                outputs=chat_model_status
            )
            
            # –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å —á–∞—Ç–∞
            chat = gr.ChatInterface(
                fn=chatbot,
                additional_inputs=[chat_model_selector, lora_selector],
                title="–ß–∞—Ç —Å –±–æ—Ç–æ–º",
                description="–û–±—â–∞–π—Ç–µ—Å—å —Å –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é. –ù–µ –∑–∞–±—É–¥—å—Ç–µ –≤—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å –∏–∑ —Å–ø–∏—Å–∫–∞ –≤—ã—à–µ!"
            )

    return demo

def launch_ui():
    demo = create_ui()
    demo.launch(server_name="0.0.0.0", server_port=7860, share=False)

def refresh_train_models():
    """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        available_models = get_available_models()
        
        # –ï—Å–ª–∏ —Å–ø–∏—Å–æ–∫ –ø—É—Å—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
        if not available_models:
            logger.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –º–æ–¥–µ–ª–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            return [], "–ù–µ –Ω–∞–π–¥–µ–Ω–æ –º–æ–¥–µ–ª–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª—å –≤–æ –≤–∫–ª–∞–¥–∫–µ '–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π'."
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è –≤—ã–ø–∞–¥–∞—é—â–µ–≥–æ —Å–ø–∏—Å–∫–∞
        model_names = list(available_models.keys())
        logger.info(f"–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {model_names}")
        return model_names, f"–ù–∞–π–¥–µ–Ω–æ {len(model_names)} –º–æ–¥–µ–ª–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {str(e)}")
        logger.exception("–ü–æ–ª–Ω—ã–π —Å—Ç–µ–∫ –æ—à–∏–±–∫–∏:")
        return [], f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {str(e)}"

def clear_model_cache(exclude_model=None):
    """–û—á–∏—â–∞–µ—Ç –∫—ç—à –º–æ–¥–µ–ª–µ–π, –∫—Ä–æ–º–µ –∏—Å–∫–ª—é—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    global MODEL_CACHE, TOKENIZER_CACHE
    
    models_to_remove = [model for model in MODEL_CACHE.keys() if model != exclude_model]
    for model in models_to_remove:
        logger.info(f"–£–¥–∞–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ {model} –∏–∑ –∫—ç—à–∞")
        del MODEL_CACHE[model]
    
    # –û—á–∏—â–∞–µ–º –∫—ç—à —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–æ–≤, –∫—Ä–æ–º–µ –∏—Å–∫–ª—é—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
    tokenizers_to_remove = [t for t in TOKENIZER_CACHE.keys() if t != exclude_model]
    for t in tokenizers_to_remove:
        logger.info(f"–£–¥–∞–ª–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ {t} –∏–∑ –∫—ç—à–∞")
        del TOKENIZER_CACHE[t]
    
    # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –≤—ã–∑—ã–≤–∞–µ–º —Å–±–æ—Ä—â–∏–∫ –º—É—Å–æ—Ä–∞
    import gc
    gc.collect()
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø –∫ CUDA, –æ—á–∏—â–∞–µ–º –∫—ç—à
    try:
        import torch
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            logger.info("CUDA –∫—ç—à –æ—á–∏—â–µ–Ω")
    except:
        pass
    
    return f"–ö—ç—à –º–æ–¥–µ–ª–µ–π –æ—á–∏—â–µ–Ω. –û—Å—Ç–∞–≤–ª–µ–Ω–∞ —Ç–æ–ª—å–∫–æ –º–æ–¥–µ–ª—å {exclude_model if exclude_model else '–Ω–µ—Ç'}"

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ—Å—Ç—É–ø–Ω—ã—Ö LoRA –∞–¥–∞–ø—Ç–µ—Ä–æ–≤
def get_available_loras():
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö LoRA –∞–¥–∞–ø—Ç–µ—Ä–æ–≤"""
    available_loras = []
    lora_dir = ADAPTER_DIR
    
    logger.info(f"–ü–æ–∏—Å–∫ LoRA –∞–¥–∞–ø—Ç–µ—Ä–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {lora_dir}")
    if os.path.exists(lora_dir):
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –≤ –ø–∞–ø–∫–µ adapters, –∏—Å–∫–ª—é—á–∞—è checkpoint-*
        loras = [d for d in os.listdir(lora_dir) if os.path.isdir(os.path.join(lora_dir, d)) and not d.startswith("checkpoint-")]
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ LoRA –∞–¥–∞–ø—Ç–µ—Ä–æ–≤: {len(loras)}")
        logger.info(f"–°–ø–∏—Å–æ–∫ LoRA –∞–¥–∞–ø—Ç–µ—Ä–æ–≤: {loras}")
        
        for lora in loras:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è LoRA –∞–¥–∞–ø—Ç–µ—Ä–∞
            lora_path = os.path.join(lora_dir, lora)
            adapter_config = os.path.join(lora_path, "adapter_config.json")
            adapter_model = os.path.join(lora_path, "adapter_model.bin")
            
            if os.path.exists(adapter_config) and (os.path.exists(adapter_model) or any(f.endswith(".bin") or f.endswith(".safetensors") for f in os.listdir(lora_path))):
                # –ü–æ–ª—É—á–∞–µ–º –∏–º—è –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –∏–∑ –∏–º–µ–Ω–∏ –∞–¥–∞–ø—Ç–µ—Ä–∞
                base_model_name = lora.split("-")[0].replace("_", "/")
                available_loras.append({
                    "name": lora,
                    "path": lora_path,
                    "base_model": base_model_name
                })
    
    return available_loras

if __name__ == "__main__":
    launch_ui()