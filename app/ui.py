import gradio as gr
import threading
import os
import shutil
import requests
from app.trainer import train_lora, log_path
import time
from transformers import AutoModelForCausalLM, AutoTokenizer
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

UPLOAD_DIR = "data/uploads"
ADAPTER_DIR = "adapters"
MODELS_DIR = "models"

os.makedirs(UPLOAD_DIR, exist_ok=True)
os.makedirs(ADAPTER_DIR, exist_ok=True)
os.makedirs(MODELS_DIR, exist_ok=True)

# –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
DOWNLOADABLE_MODELS = {
    "TinyLlama": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    "Mistral": "mistralai/Mistral-7B-v0.1",
    "Falcon": "tiiuae/falcon-7b"
}

def check_model_availability(model_name):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
    model_path = os.path.join(MODELS_DIR, model_name)
    return os.path.exists(model_path)

def get_available_models():
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    available_models = {}
    for name in DOWNLOADABLE_MODELS.keys():
        if check_model_availability(name):
            available_models[name] = name
    return available_models

def download_model(model_name, model_id):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å"""
    try:
        logger.info(f"–ù–∞—á–∞–ª–æ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ {model_name}")
        # –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞
        tokenizer = AutoTokenizer.from_pretrained(model_id)
        tokenizer.save_pretrained(os.path.join(MODELS_DIR, model_name))
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
        model = AutoModelForCausalLM.from_pretrained(
            model_id,
            torch_dtype="auto",
            device_map="auto"
        )
        model.save_pretrained(os.path.join(MODELS_DIR, model_name))
        
        logger.info(f"–ú–æ–¥–µ–ª—å {model_name} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        return f"‚úÖ –ú–æ–¥–µ–ª—å {model_name} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞"
    except Exception as e:
        error_msg = f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏ {model_name}: {str(e)}"
        logger.error(error_msg)
        return error_msg

def save_file(file):
    filepath = os.path.join(UPLOAD_DIR, file.name)
    with open(filepath, "wb") as f:
        shutil.copyfileobj(file, f)
    return f"–ó–∞–≥—Ä—É–∂–µ–Ω —Ñ–∞–π–ª: {file.name}"

def start_training(model_name, r, alpha, dropout):
    train_lora(model_name=model_name, r=int(r), alpha=int(alpha), dropout=float(dropout))
    return "‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–ø—É—â–µ–Ω–æ"

def get_logs():
    if os.path.exists(log_path):
        with open(log_path, "r") as f:
            return f.read()
    return "–õ–æ–≥–∏ –ø–æ–∫–∞ –ø—É—Å—Ç—ã"

def chatbot(msg):
    return f"(–±–æ—Ç –æ—Ç–≤–µ—á–∞–µ—Ç): {msg}"

def create_ui():
    with gr.Blocks(title="LoRA Center") as demo:
        gr.Markdown("# –¶–µ–Ω—Ç—Ä –æ–±—É—á–µ–Ω–∏—è LoRA-–±–æ—Ç–æ–≤")

        with gr.Tabs():
            with gr.Tab("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π"):
                gr.Markdown("### –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏")
                model_download = gr.Dropdown(
                    label="–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏",
                    choices=list(DOWNLOADABLE_MODELS.keys()),
                    interactive=True
                )
                download_button = gr.Button("–ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å")
                download_status = gr.Textbox(label="–°—Ç–∞—Ç—É—Å –∑–∞–≥—Ä—É–∑–∫–∏")
                
                def handle_download(model_name):
                    if model_name:
                        model_id = DOWNLOADABLE_MODELS[model_name]
                        return download_model(model_name, model_id)
                    return "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å"
                
                download_button.click(
                    handle_download,
                    inputs=model_download,
                    outputs=download_status
                )

            with gr.Tab("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤"):
                upload = gr.File(file_types=[".txt", ".docx", ".pdf"], file_count="multiple")
                upload_button = gr.Button("–ó–∞–≥—Ä—É–∑–∏—Ç—å")
                output = gr.Textbox()
                upload_button.click(fn=lambda files: "\n".join([save_file(f) for f in files]), inputs=upload, outputs=output)

            with gr.Tab("üß† –û–±—É—á–µ–Ω–∏–µ LoRA"):
                with gr.Row():
                    with gr.Column():
                        available_models = get_available_models()
                        model_selector = gr.Dropdown(
                            label="–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å",
                            choices=list(available_models.keys()),
                            value=None,
                            interactive=True
                        )
                        model_name = gr.Textbox(
                            label="–ò–ª–∏ –≤–≤–µ–¥–∏—Ç–µ HuggingFace ID",
                            value="",
                            interactive=True
                        )
                        def sync_model(choice):
                            return available_models.get(choice, "")
                        model_selector.change(sync_model, inputs=model_selector, outputs=model_name)
                    
                    with gr.Column():
                        r = gr.Number(label="r", value=8)
                        alpha = gr.Number(label="alpha", value=32)
                        dropout = gr.Number(label="dropout", value=0.05)
                
                train_button = gr.Button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ")
                train_output = gr.Textbox()
                train_button.click(start_training, inputs=[model_name, r, alpha, dropout], outputs=train_output)

            with gr.Tab("üìä –õ–æ–≥–∏ –æ–±—É—á–µ–Ω–∏—è"):
                log_output = gr.Textbox(label="–õ–æ–≥–∏", lines=20)
                refresh_button = gr.Button("–û–±–Ω–æ–≤–∏—Ç—å –ª–æ–≥–∏")
                refresh_button.click(get_logs, outputs=log_output)
                # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ª–æ–≥–æ–≤ –∫–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥
                demo.load(get_logs, outputs=log_output, every=5)

            with gr.Tab("ü§ñ –ß–∞—Ç —Å –±–æ—Ç–æ–º"):
                chat = gr.ChatInterface(fn=chatbot)

    return demo

def launch_ui():
    demo = create_ui()
    demo.launch(server_name="0.0.0.0", server_port=7860, share=False)